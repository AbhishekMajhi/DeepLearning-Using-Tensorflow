{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "OMdut",
      "launcher_item_id": "bbBOL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Autonomous_driving_application_Car_detection_v3a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq6qfbGvrNon"
      },
      "source": [
        "# Autonomous driving - Car detection\n",
        "Ideas in this notebook are from the two YOLO papers: [Redmon et al., 2016](https://arxiv.org/abs/1506.02640) and [Redmon and Farhadi, 2016](https://arxiv.org/abs/1612.08242). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nQikTD32qQ4"
      },
      "source": [
        "import colorsys\n",
        "import imghdr\n",
        "import os\n",
        "import random\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def read_classes(classes_path):\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def read_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "        anchors = [float(x) for x in anchors.split(',')]\n",
        "        anchors = np.array(anchors).reshape(-1, 2)\n",
        "    return anchors\n",
        "\n",
        "def generate_colors(class_names):\n",
        "    hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    random.seed(None)  # Reset seed to default.\n",
        "    return colors\n",
        "\n",
        "def scale_boxes(boxes, image_shape):\n",
        "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
        "    height = image_shape[0]\n",
        "    width = image_shape[1]\n",
        "    image_dims = K.stack([height, width, height, width])\n",
        "    image_dims = K.reshape(image_dims, [1, 4])\n",
        "    boxes = boxes * image_dims\n",
        "    return boxes\n",
        "\n",
        "def preprocess_image(img_path, model_image_size):\n",
        "    image_type = imghdr.what(img_path)\n",
        "    image = Image.open(img_path)\n",
        "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
        "    image_data = np.array(resized_image, dtype='float32')\n",
        "    image_data /= 255.\n",
        "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
        "    return image, image_data\n",
        "\n",
        "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
        "    \n",
        "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
        "    thickness = (image.size[0] + image.size[1]) // 300\n",
        "\n",
        "    for i, c in reversed(list(enumerate(out_classes))):\n",
        "        predicted_class = class_names[c]\n",
        "        box = out_boxes[i]\n",
        "        score = out_scores[i]\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textsize(label, font)\n",
        "\n",
        "        top, left, bottom, right = box\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
        "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        del draw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRtSMQ35rNop"
      },
      "source": [
        "## Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFAatXf4rNoq"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Lambda, Conv2D\n",
        "from keras.models import load_model, Model\n",
        "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
        "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS3hOu3RrNo5"
      },
      "source": [
        "# yolo filter boxes\n",
        "\n",
        "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
        "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
        "    \n",
        "    Arguments:\n",
        "    box_confidence -- tensor of shape (19, 19, 5, 1)\n",
        "    boxes -- tensor of shape (19, 19, 5, 4)\n",
        "    box_class_probs -- tensor of shape (19, 19, 5, 80)\n",
        "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
        "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
        "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute box scores\n",
        "    box_scores = box_confidence * box_class_probs\n",
        "    \n",
        "    \n",
        "    #  Finding the box_classes using the max box_scores\n",
        "    box_classes = K.argmax(box_scores, axis = -1) # class having maximum box score\n",
        "    box_class_scores = K.max(box_scores, axis= -1) # finding the box score of that max one.\n",
        "    \n",
        "    \n",
        "    # Creating a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
        "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
        "    filtering_mask = (box_class_scores >= threshold)\n",
        "  \n",
        "    \n",
        "    # Applying the mask to box_class_scores, boxes and box_classes\n",
        "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
        "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
        "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tl5X1pXrNpF"
      },
      "source": [
        "# Calculating iou(IoU) between box1 and box2\n",
        "    \n",
        "\n",
        "def iou(box1, box2):\n",
        "    \"\"\" \n",
        "    Arguments:\n",
        "    box1 -- first box, list object with coordinates (box1_x1, box1_y1, box1_x2, box_1_y2)\n",
        "    box2 -- second box, list object with coordinates (box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \"\"\"\n",
        "\n",
        "    # Assigning variable names to coordinates for clarity\n",
        "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
        "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
        "    #print(box1_x1, box1_y1, box1_x2, box1_y2)\n",
        "    #print(box2_x1, box2_y1, box2_x2, box2_y2)\n",
        "    \n",
        "    # Calculating the (yi1, xi1, yi2, xi2) coordinates of the intersection of box1 and box2. Calculate its Area.\n",
        "    xi1 = max(box1[0], box2[0])\n",
        "    yi1 = max(box1[1], box2[1])\n",
        "    xi2 = min(box1[2], box2[2])\n",
        "    yi2 = min(box1[3], box2[3])\n",
        "\n",
        "    \n",
        "    inter_width = (xi2 - xi1)\n",
        "    inter_height = (yi2 - yi1)\n",
        "    inter_area = np.maximum((xi2 - xi1), 0)*np.maximum((yi2 - yi1),0)\n",
        "    print(\"inter_area:\", inter_area)\n",
        "     \n",
        "\n",
        "    # Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
        "    box1_area = (box1_y2 - box1_y1) * (box1_x2 - box1_x1)\n",
        "    box2_area = (box2_y2 - box2_y1) * (box2_x2 - box2_x1)\n",
        "    union_area = (box1_area + box2_area) - inter_area\n",
        "    \n",
        "    # compute the IoU\n",
        "    iou = inter_area / union_area\n",
        "    \n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVek5YLurNpQ"
      },
      "source": [
        "# Applying yolo_non_max_suppression to set of boxes\n",
        "\n",
        "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
        "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
        "    classes -- tensor of shape (None,), output of yolo_filter_boxes()\n",
        "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
        "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (, None), predicted score for each box\n",
        "    boxes -- tensor of shape (4, None), predicted box coordinates\n",
        "    classes -- tensor of shape (, None), predicted class for each box\n",
        "    \"\"\"\n",
        "    \n",
        "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
        "    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\n",
        "    \n",
        "\n",
        "    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
        "\n",
        "    scores = K.gather(scores, nms_indices)\n",
        "    boxes = K.gather(boxes, nms_indices)\n",
        "    classes = K.gather(classes, nms_indices)\n",
        "    \n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aSgMU9urNpa"
      },
      "source": [
        "# yolo eval\n",
        "\n",
        "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
        "    \"\"\" \n",
        "    Arguments:\n",
        "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
        "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
        "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
        "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
        "                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)\n",
        "    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)\n",
        "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
        "    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
        "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
        "    \n",
        "    Returns:\n",
        "    scores -- tensor of shape (None, ), predicted score for each box\n",
        "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
        "    classes -- tensor of shape (None,), predicted class for each box\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve outputs of the YOLO model\n",
        "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
        "\n",
        "    # Converting boxes to be ready for filtering functions (convert boxes box_xy and box_wh to corner coordinates)\n",
        "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
        "\n",
        "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)\n",
        "    \n",
        "    # Scale boxes back to original image shape.\n",
        "    boxes = scale_boxes(boxes, image_shape)\n",
        "\n",
        "    # Use one of the functions you've implemented to perform Non-max suppression with \n",
        "    # maximum number of boxes set to max_boxes and a threshold of iou_threshold\n",
        "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes,iou_threshold)\n",
        "    \n",
        "    return scores, boxes, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYxrARfbrNpl"
      },
      "source": [
        "## 3 - Test YOLO pre-trained model on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-U1nmCJrNpl"
      },
      "source": [
        "Here we gonna use a pre-trained model and test it on the car detection dataset.  We'll need a session to execute the computation graph and evaluate the tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKyYgDnrNpm"
      },
      "source": [
        "sess = K.get_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2OHGidDrNpr"
      },
      "source": [
        "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
        "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
        "image_shape = (720., 1280.)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH5VL5GPrNpu"
      },
      "source": [
        "### 3.2 - Loading a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd7sZ3nVrNpv"
      },
      "source": [
        "yolo_model = load_model(\"model_data/yolo.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b5dAyIhrNp0"
      },
      "source": [
        "This loads the weights of a trained YOLO model. Here's a summary of the layers your model contains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQH5OkxgrNp0"
      },
      "source": [
        "yolo_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qD-jT81rNp4"
      },
      "source": [
        "###  Convert output of the model to usable bounding box tensors\n",
        "\n",
        "The output of `yolo_model` is a (m, 19, 19, 5, 85) tensor that needs to pass through non-trivial processing and conversion.\n",
        "\n",
        " `yolo_head` implementation can find the function definition in the file ['keras_yolo.py'](https://github.com/allanzelener/YAD2K/blob/master/yad2k/models/keras_yolo.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO1SXhahrNp5"
      },
      "source": [
        "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJNX2KvGrNp9"
      },
      "source": [
        "###  Filtering boxes\n",
        "\n",
        "`yolo_outputs` gave us all the predicted boxes of `yolo_model` in the correct format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kjyNKB8rNp9"
      },
      "source": [
        "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4VyIkN6rNqB"
      },
      "source": [
        "### Running the graph on an image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zey7eLTmrNqB"
      },
      "source": [
        "def predict(sess, image_file):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
        "    image_file -- name of an image stored in the \"images\" folder.\n",
        "    \n",
        "    Returns:\n",
        "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
        "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
        "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
        " \n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess  image\n",
        "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
        "\n",
        "    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict = {yolo_model.input:image_data,\n",
        "                                                                                         K.learning_phase():0})\n",
        "    \n",
        "\n",
        "    # Printing predictions info\n",
        "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
        "    # Generating colors for drawing bounding boxes.\n",
        "    colors = generate_colors(class_names)\n",
        "    # Drawing bounding boxes on the image file\n",
        "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
        "    # Save the predicted bounding box on the image\n",
        "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
        "    # Displaying the results in the notebook\n",
        "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
        "    imshow(output_image)\n",
        "    \n",
        "    return out_scores, out_boxes, out_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEFp3s2ZrNqF"
      },
      "source": [
        "Run the following cell on the \"test.jpg\" image to verify that your function is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UxTX41MfrNqF"
      },
      "source": [
        "out_scores, out_boxes, out_classes = predict(sess, \"test.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsgHIVEMrNqM"
      },
      "source": [
        "**References**: The ideas presented in this notebook came primarily from the two YOLO papers. The implementation here also took significant inspiration and used many components from Allan Zelener's GitHub repository. The pre-trained weights used in this exercise came from the official YOLO website. \n",
        "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) (2015)\n",
        "- Joseph Redmon, Ali Farhadi - [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (2016)\n",
        "- Allan Zelener - [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)\n",
        "- The official YOLO website (https://pjreddie.com/darknet/yolo/) "
      ]
    }
  ]
}
